---
title: "Lab3 block2 732A95"
author: "Anton Persson antpe404"
date: "16 december 2016"
output: pdf_document
---

#Assignment 1 High dimensional methods

The first assignment is about different methods to deal with wide data.

##Assignment 1.1

I divided the data into training and test according to the instruction. The nearest shrunken centroid classification was done and the required results are presented below.

```{r, echo=F, message=F, warning=F, results='hide'}
#Assignment 1
data<-read.csv2("data/data.csv", header=T, sep=";")
#Wide data.
set.seed(12345)
data<-data[sample(1:nrow(data)), ] #Shufflar raderna
data$Conference<-as.factor(data$Conference)
train<-data[1:45, ]
test<-data[46:64, ]

#1.1

library(pamr)
which_col<-which(colnames(train)=="Conference")
x<-t(train[,-which_col]) #Alla utom Conf
y<-train[, which_col] #endast Conf
#head(as.character( 1:nrow(x) ))
mydata<-list(x=x,y=y,geneid=as.character(1:nrow(x)), genenames=rownames(x))
model<-pamr.train(mydata,threshold=seq(0,4, 0.1))

cv_model<-pamr.cv(model,mydata)
#cv_model$error#.13 lägst, fr 0.7-1.8 och 2.6

```

```{r, echo=F, warning=F, message=F}
print(cv_model) #Här kan man se samma, 0.7-1.8 eller 2.6

```

From the table above, I conclude that a threshold between 0.7-1.8 or 2.6 generates the lowest error. I choose 2.6 as threshold because of simplicity. This will generate 21 selected features, notated as \textit{nonzero} in the output above. 
The figure below visualizes the table above. The plot on top in the figure below says that above mentioned thresholds minimizes the error.

```{r, echo=F, warning=F, message=F, fig.height=9, fig.width=5}
pamr.plotcv(cv_model)

```

The ten most important features for the model with 2.6 as threshold is visualized in a cendriod plot below.

```{r, echo=F, message=F, warning=F}
chosen_model<-pamr.train(mydata,threshold=2.6) #Väljer 2.6 för simplicity.
pamr.plotcen(chosen_model, mydata, threshold=2.6)

```

The deafult plot in pamr doesn't have a brilliant layout, why it's kind of hard to read which variables are actually chosen. For clarity I decided to list them in a more proper way. The ten most contributing features are thus listed below.

```{r, echo=F, message=F, warning=F, results="hide"}
cv_vars<-pamr.listgenes(chosen_model,mydata,threshold=2.6)
#cv_vars[,1] #Variablerna
my_variables_index2<-as.numeric(cv_vars[,1])
my_variables2<-colnames(data)[my_variables_index2]
#length(my_variables2)

```

```{r, echo=F}
cat(paste(my_variables2[1:10], collapse="\n")) 

```


I'd say that the words are reasonable. I can see why you'd mention words like \textit{paper}, \textit{submission}, \textit{candidates}, \textit{published}, \textit{dates} and \textit{conference} in a mail about conferences.
Finally, the test error is presented below.

```{r, echo=F}
x_test<-t(test[,-which_col]) #Alla utom Conf
y_test<-test[, which_col] #endast Conf
#head(as.character( 1:nrow(x) ))
my_testdata<-list(x=x_test,y=y_test,geneid=as.character(1:nrow(x)), genenames=rownames(x))

conf_mat_NSC<-table(preds=pamr.predict(chosen_model,my_testdata$x,threshold = 2.6),truth=my_testdata$y)
#conf_mat_NSC

number_of_features_NSC<-length(my_variables2)
test_error_rate_NSC<-((conf_mat_NSC[1,2]+conf_mat_NSC[2,1])/
  sum(conf_mat_NSC))
test_error_rate_NSC
```

\newpage

##Assignment 1.2

In this assignment I'm supposed to compute the error rate and number of contributing features for two more methods, elastic net and support vector machine. I start off with elastic net.

###Assignment 1.2a

The instructions defines the type of response and value of $\alpha$ for me. I do use the function cv.glmnet to decide penalty by cross validation. The number of features and test error rate is presented below.

```{r, echo=F, message=F, warning=F}
#1.2a
library(glmnet)  

train_x<-as.matrix(train[,-which_col])
train_y<-as.factor(train[,which_col])
test_x<-as.matrix(test[, -which_col])
test_y<-as.factor(test[,which_col])

set.seed(12345)
elastic<-cv.glmnet(x=train_x, y=train_y, alpha=.5, family="binomial")
#plot(elastic)

elastic_coe<-coefficients(elastic)
elastic_coeff<-elastic_coe[,1]
elastic_coef<-elastic_coeff[elastic_coeff!=0] #Tar ut de som inte är 0.

elastic_coefficients<-as.data.frame(cbind(coef=as.numeric(elastic_coef), variable=names(elastic_coef)))
#12 variabler med coef skild fr 0.
fitted<-predict(elastic, newx = test_x,
      s = elastic$lambda.1se, type="class") #default s.

#fitted
#length(fitted)
fitted<-as.numeric(fitted)

number_of_features_elastic<-nrow(elastic_coefficients)-1
conf_mat_elastic<-table(preds=fitted, truth=test_y)
test_error_rate_elastic<-((conf_mat_elastic[1,2]+conf_mat_elastic[2,1])/
  sum(conf_mat_elastic))

reslist<-list(test_error_rate_elastic=test_error_rate_elastic, number_of_features_elastic=number_of_features_elastic)

reslist


```

###Assignment 1.2b

The test error and number of contributing features for a SVM with \textit{vanilladot} kernel are presented below.

```{r, echo=F, warning=F, message=F}
#1.2b
library(kernlab)
set.seed(12345)
my_svm<-ksvm(x=train_x, y=train_y, kernel="vanilladot", scale=FALSE, type="C-svc")

fitted_svm<-predict(my_svm, test_x)
conf_mat_svm<-table(preds=fitted_svm, truth=test_y)
#conf_mat_svm

test_error_rate_svm<-(conf_mat_svm[1,2]+conf_mat_svm[2,1])/sum(conf_mat_svm)

number_of_features_svm<-my_svm@nSV

reslist2<-list(test_error_rate_svm=test_error_rate_svm, number_of_features_svm=number_of_features_svm)

reslist2

```

Finally the three methods used above, nearest shrunken centroid method, elastic net and support vector machine.